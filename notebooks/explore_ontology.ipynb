{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Ontological connection checking\n",
    "\n",
    "Here I want to play around with ontological type checking in `pyiron_workflow` using `semantikon`'s `u` annotations."
   ],
   "id": "f672db8683348bf7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T19:57:16.622461Z",
     "start_time": "2025-08-27T19:57:15.758935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import rdflib\n",
    "\n",
    "from semantikon.metadata import u\n",
    "\n",
    "import pyiron_workflow as pwf\n",
    "from pyiron_workflow import suggest\n",
    "from pyiron_workflow.channels import ChannelConnectionError\n",
    "from pyiron_workflow.nodes.composite import FailedChildError\n",
    "\n",
    "\n",
    "EX = rdflib.Namespace(\"http://www.example.org/\")\n",
    "\n",
    "class Meal: ...\n",
    "\n",
    "class Garbage: ...\n",
    "\n",
    "@pwf.as_function_node(\"pizza\")\n",
    "def prepare_pizza() -> u(Meal, uri=EX.Pizza):\n",
    "    return Meal()\n",
    "\n",
    "@pwf.as_function_node(\"unidentified_meal\")\n",
    "def prepare_non_ontological_meal() -> Meal:\n",
    "    return Meal()\n",
    "\n",
    "@pwf.as_function_node(\"rice\")\n",
    "def prepare_rice() -> u(Meal, uri=EX.Rice):\n",
    "    return Meal()\n",
    "\n",
    "@pwf.as_function_node(\"garbage\")\n",
    "def prepare_garbage() -> u(Garbage, uri=EX.Garbage):\n",
    "    return Garbage()\n",
    "\n",
    "@pwf.as_function_node(\"garbage\")\n",
    "def prepare_unhinted_garbage():\n",
    "    return Garbage()\n",
    "\n",
    "@pwf.as_function_node(\"verdict\")\n",
    "def eat(meal: u(Meal, uri=EX.Meal)) -> str:\n",
    "    return f\"Yummy {meal.__class__.__name__} meal\"\n",
    "\n",
    "@pwf.as_function_node(\"verdict\")\n",
    "def eat_pizza(meal: u(Meal, uri=EX.Pizza)) -> str:\n",
    "    return f\"Yummy {meal.__class__.__name__} pizza\""
   ],
   "id": "996ce3d6152f1beb",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Both fully hinted\n",
    "\n",
    "Works fine"
   ],
   "id": "cf1e5e273013acb1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T19:57:17.508087Z",
     "start_time": "2025-08-27T19:57:16.626852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "wf = pwf.Workflow(\"ontoflow\")\n",
    "wf.make = prepare_pizza()\n",
    "wf.eat = eat_pizza(wf.make)\n",
    "wf()"
   ],
   "id": "807c93a2f4436b4f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eat__verdict': 'Yummy Meal pizza'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Upstream type hint is missing\n",
    "\n",
    "Standard `pyiron_workflow` typing behaviour: we are allowed to form the connection (since the source has no hint), but at runtime, we will fail when we try to actually assign the value"
   ],
   "id": "b8e91ece9a45bf7f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T19:57:17.597557Z",
     "start_time": "2025-08-27T19:57:17.592248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "wf = pwf.Workflow(\"no_type\")\n",
    "wf.make = prepare_unhinted_garbage()\n",
    "wf.eat = eat_pizza(wf.make)\n",
    "try:\n",
    "    wf.recovery = None\n",
    "    wf()\n",
    "except FailedChildError as e:\n",
    "    print(e)"
   ],
   "id": "3fde7d3acb113d85",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/no_type encountered error in child: {'/no_type/eat.accumulate_and_run': TypeError(\"The channel /no_type/eat.meal cannot take the value `<__main__.Garbage object at 0x1272fad80>` (<class '__main__.Garbage'>) because it is not compliant with the type hint typing.Annotated[__main__.Meal, ('uri', rdflib.term.URIRef('http://www.example.org/Pizza'))]\")}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Upstream type hint is wrong\n",
    "\n",
    "Standard `pyiron_workflow` typing behaviour: we're not even allowed to form the connection -- the recipe would be invalid"
   ],
   "id": "9af06c9ae9a7512e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T19:57:17.616058Z",
     "start_time": "2025-08-27T19:57:17.612449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "wf = pwf.Workflow(\"no_type\")\n",
    "wf.make = prepare_garbage()\n",
    "try:\n",
    "    wf.eat = eat_pizza(wf.make)\n",
    "except ChannelConnectionError as e:\n",
    "    print(e)"
   ],
   "id": "a530586921463886",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The channel /no_type/make.garbage (<class 'pyiron_workflow.mixin.injection.OutputDataWithInjection'>) has the correct type (<class 'pyiron_workflow.channels.OutputData'>) to connect with /eat_pizza.meal (<class 'pyiron_workflow.channels.InputData'>), but is not a valid connection.Please check type hints, etc. /no_type/make.garbage.type_hint = typing.Annotated[__main__.Garbage, ('uri', rdflib.term.URIRef('http://www.example.org/Garbage'))]; /eat_pizza.meal.type_hint = typing.Annotated[__main__.Meal, ('uri', rdflib.term.URIRef('http://www.example.org/Pizza'))]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "So far, so good: `u` decoration has no negative impact on the existing type hint checking procedures",
   "id": "5995ff2b2e009aee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Upstream ontological hint is missing\n",
    "\n",
    "New ontological behaviour: As with type hints, if one side is missing we just let things pass. Unlike type hints, we can also _execute_ the workflow, because the ontologies only impact the recipe-level behaviour, not the instance behaviour!"
   ],
   "id": "ca34d53309189d96"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T19:57:17.672132Z",
     "start_time": "2025-08-27T19:57:17.668003Z"
    }
   },
   "cell_type": "code",
   "source": [
    "wf = pwf.Workflow(\"no_ontology\")\n",
    "wf.make = prepare_non_ontological_meal()\n",
    "wf.eat = eat_pizza(wf.make)\n",
    "wf()"
   ],
   "id": "d6d324aff20c4e63",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eat__verdict': 'Yummy Meal pizza'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Upstream ontological hint is WRONG\n",
    "\n",
    "New ontological behaviour: new ontological type checking now prevents us from even forming the ontologically invalid connection!"
   ],
   "id": "87f8ae15183930fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T19:57:17.728769Z",
     "start_time": "2025-08-27T19:57:17.686390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "wf = pwf.Workflow(\"failed_ontology\")\n",
    "wf.make = prepare_rice()\n",
    "try:\n",
    "    wf.eat = eat_pizza(wf.make)\n",
    "except ChannelConnectionError as e:\n",
    "    print(e)"
   ],
   "id": "316fea01813d2c64",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The channel /failed_ontology/make.rice (<class 'pyiron_workflow.mixin.injection.OutputDataWithInjection'>) has the correct type (<class 'pyiron_workflow.channels.OutputData'>) to connect with /eat_pizza.meal (<class 'pyiron_workflow.channels.InputData'>), but is not a valid connection.Please check type hints, etc. /failed_ontology/make.rice.type_hint = typing.Annotated[__main__.Meal, ('uri', rdflib.term.URIRef('http://www.example.org/Rice'))]; /eat_pizza.meal.type_hint = typing.Annotated[__main__.Meal, ('uri', rdflib.term.URIRef('http://www.example.org/Pizza'))]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Downstream ontological hint is less specific\n",
    "\n",
    "This should work fine..."
   ],
   "id": "5b883e1acf6aa7c4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T19:57:17.777256Z",
     "start_time": "2025-08-27T19:57:17.735083Z"
    }
   },
   "cell_type": "code",
   "source": [
    "wf = pwf.Workflow(\"relaxed_ontology\")\n",
    "wf.make = prepare_rice()\n",
    "try:\n",
    "    wf.eat = eat(wf.make)\n",
    "except ChannelConnectionError as e:\n",
    "    print(e)"
   ],
   "id": "230dba9264a053e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The channel /relaxed_ontology/make.rice (<class 'pyiron_workflow.mixin.injection.OutputDataWithInjection'>) has the correct type (<class 'pyiron_workflow.channels.OutputData'>) to connect with /eat.meal (<class 'pyiron_workflow.channels.InputData'>), but is not a valid connection.Please check type hints, etc. /relaxed_ontology/make.rice.type_hint = typing.Annotated[__main__.Meal, ('uri', rdflib.term.URIRef('http://www.example.org/Rice'))]; /eat.meal.type_hint = typing.Annotated[__main__.Meal, ('uri', rdflib.term.URIRef('http://www.example.org/Meal'))]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "But! We forgot something! This form of failure is known from the `semantikon` notebook whence these demonstration workflow spring: we never informed the ontology that \"rice\" is a subclass of \"meal\"!\n",
    "\n",
    "We let the ontology know this by adding the corresponding triple to our `rdflib.Graph`. In `pyiron_workflow` we can manage this by pre-populating a `knowledge: rdflib.Graph` property on the graph root (i.e. top-most object) as follows:"
   ],
   "id": "9a332e6a04dc2bd2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T19:57:17.853546Z",
     "start_time": "2025-08-27T19:57:17.781979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "wf = pwf.Workflow(\"relaxed_ontology\")\n",
    "\n",
    "wf.knowledge = rdflib.Graph()\n",
    "wf.knowledge.add((EX.Rice, rdflib.RDFS.subClassOf, EX.Meal))\n",
    "\n",
    "wf.make = prepare_rice()\n",
    "wf.eat = eat(wf.make)\n",
    "wf()"
   ],
   "id": "cb2a13e6144e6378",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eat__verdict': 'Yummy Meal meal'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Ontological triples\n",
    "\n",
    "Alright, for our simple pizza example things are working beautifully. Let's try it with the clothes example."
   ],
   "id": "574ac2f3813504ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T19:57:17.874891Z",
     "start_time": "2025-08-27T19:57:17.867896Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EX = rdflib.Namespace(\"http://www.example.org/\")\n",
    "\n",
    "class Clothes:\n",
    "    pass\n",
    "\n",
    "@pwf.as_function_node\n",
    "def wash(clothes: u(Clothes, uri=EX.Clothes)) -> u(\n",
    "    Clothes,\n",
    "    triples=(EX.hasProperty, EX.cleaned),\n",
    "    derived_from=\"inputs.clothes\"\n",
    "):\n",
    "    ...\n",
    "    return clothes\n",
    "\n",
    "@pwf.as_function_node\n",
    "def dye(clothes: u(Clothes, uri=EX.Clothes), color=\"blue\") -> u(\n",
    "    Clothes,\n",
    "    triples=(EX.hasProperty, EX.color),\n",
    "    derived_from=\"inputs.clothes\",\n",
    "):\n",
    "    ...\n",
    "    return clothes\n",
    "\n",
    "@pwf.as_function_node\n",
    "def sell(\n",
    "    clothes: u(\n",
    "        Clothes,\n",
    "        uri=EX.Clothes,\n",
    "        restrictions=(\n",
    "            ((rdflib.OWL.onProperty, EX.hasProperty), (rdflib.OWL.someValuesFrom, EX.cleaned)),\n",
    "            ((rdflib.OWL.onProperty, EX.hasProperty), (rdflib.OWL.someValuesFrom, EX.color)),\n",
    "        )\n",
    "    )\n",
    ") -> int:\n",
    "    price = 10\n",
    "    return price"
   ],
   "id": "dceaab6f57226f07",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Now with `restrictions`\n",
    "\n",
    "In the base case, everything works fine. The restrictions are correctly parsed.\n",
    "\n",
    "Note that unlike the `semantikon` notebook, here we had to make sure that all the node inputs are also `u` annotated (even if it's just to trivially link the type to its ontology counterpart). This is because type checking only occurs in `pyiron_workflow` when _both_ sides of the connection are typed! We follow this rule for both standard data types and ontological types."
   ],
   "id": "e9bb559e718b4f66"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T19:57:18.172760Z",
     "start_time": "2025-08-27T19:57:17.887259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "my_correct_wf = pwf.Workflow(\"my_correct_workflow\")\n",
    "my_correct_wf.dyed_clothes = dye(Clothes())\n",
    "my_correct_wf.washed_clothes = wash(my_correct_wf.dyed_clothes)\n",
    "my_correct_wf.money = sell(my_correct_wf.washed_clothes)\n",
    "my_correct_wf()"
   ],
   "id": "c163d51cd2c676c2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'money__price': 10}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## As a macro\n",
    "\n",
    "This also works fine! Be careful though, here we've only demonstrated that it _can_ work for macros, and have not yet guaranteed it works for _all_ macros."
   ],
   "id": "8dd38830d50f1b73"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T19:57:18.478564Z",
     "start_time": "2025-08-27T19:57:18.178510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@pwf.as_macro_node\n",
    "def my_correct_macro(self, clothes: Clothes):\n",
    "    self.dyed_clothes = dye(clothes)\n",
    "    self.washed_clothes = wash(self.dyed_clothes)\n",
    "    self.money = sell(self.washed_clothes)\n",
    "    return self.money\n",
    "\n",
    "correct_m = my_correct_macro(Clothes())\n",
    "correct_m()"
   ],
   "id": "f6b77dff8a1e5b84",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'money': 10}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Trivial failure\n",
    "\n",
    "If we skip a step, our `sell` `restrictions` are not fulfilled, and we sensibly fail."
   ],
   "id": "c71478fc498bdb30"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T19:57:18.544411Z",
     "start_time": "2025-08-27T19:57:18.487125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "my_wrong_wf = pwf.Workflow(\"my_wrong_workflow\")\n",
    "my_wrong_wf.washed_clothes = wash(Clothes())\n",
    "try:\n",
    "    my_wrong_wf.money = sell(my_wrong_wf.washed_clothes)\n",
    "except ChannelConnectionError as e:\n",
    "    print(e)"
   ],
   "id": "ef51d73b476d6a0b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The channel /my_wrong_workflow/washed_clothes.clothes (<class 'pyiron_workflow.mixin.injection.OutputDataWithInjection'>) has the correct type (<class 'pyiron_workflow.channels.OutputData'>) to connect with /sell.clothes (<class 'pyiron_workflow.channels.InputData'>), but is not a valid connection.Please check type hints, etc. /my_wrong_workflow/washed_clothes.clothes.type_hint = typing.Annotated[__main__.Clothes, ('triples', (rdflib.term.URIRef('http://www.example.org/hasProperty'), rdflib.term.URIRef('http://www.example.org/cleaned')), 'derived_from', 'inputs.clothes')]; /sell.clothes.type_hint = typing.Annotated[__main__.Clothes, ('uri', rdflib.term.URIRef('http://www.example.org/Clothes'), 'restrictions', (((rdflib.term.URIRef('http://www.w3.org/2002/07/owl#onProperty'), rdflib.term.URIRef('http://www.example.org/hasProperty')), (rdflib.term.URIRef('http://www.w3.org/2002/07/owl#someValuesFrom'), rdflib.term.URIRef('http://www.example.org/cleaned'))), ((rdflib.term.URIRef('http://www.w3.org/2002/07/owl#onProperty'), rdflib.term.URIRef('http://www.example.org/hasProperty')), (rdflib.term.URIRef('http://www.w3.org/2002/07/owl#someValuesFrom'), rdflib.term.URIRef('http://www.example.org/color')))))]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Macro failure\n",
    "\n",
    "When we wrap the failing code as a macro, we don't fail until we try to instantiate that macro -- that is the first time the recipe code is evaluated and ontologically evaluated, at which point we fail at the connection formation just like in the workflow example.\n",
    "\n",
    "In the future, if we move to `pyiron_workflow` decorators first producing (and validating) `flowrep` recipes and _then_ using these to create `pyiron_workflow` node classes, we'd be able to nicely fail at the macro definition time instead!"
   ],
   "id": "9b3d6a2838caaf72"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T19:57:18.611270Z",
     "start_time": "2025-08-27T19:57:18.548449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@pwf.as_macro_node\n",
    "def my_wrong_macro(self, clothes: Clothes):\n",
    "    self.washed_clothes = wash(clothes)\n",
    "    self.money = sell(self.washed_clothes)\n",
    "    return self.money\n",
    "\n",
    "try:\n",
    "    my_wrong_macro()\n",
    "except ChannelConnectionError as e:\n",
    "    print(e)"
   ],
   "id": "1520f248cef9296e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The channel /my_wrong_macro/washed_clothes.clothes (<class 'pyiron_workflow.mixin.injection.OutputDataWithInjection'>) has the correct type (<class 'pyiron_workflow.channels.OutputData'>) to connect with /sell.clothes (<class 'pyiron_workflow.channels.InputData'>), but is not a valid connection.Please check type hints, etc. /my_wrong_macro/washed_clothes.clothes.type_hint = typing.Annotated[__main__.Clothes, ('triples', (rdflib.term.URIRef('http://www.example.org/hasProperty'), rdflib.term.URIRef('http://www.example.org/cleaned')), 'derived_from', 'inputs.clothes')]; /sell.clothes.type_hint = typing.Annotated[__main__.Clothes, ('uri', rdflib.term.URIRef('http://www.example.org/Clothes'), 'restrictions', (((rdflib.term.URIRef('http://www.w3.org/2002/07/owl#onProperty'), rdflib.term.URIRef('http://www.example.org/hasProperty')), (rdflib.term.URIRef('http://www.w3.org/2002/07/owl#someValuesFrom'), rdflib.term.URIRef('http://www.example.org/cleaned'))), ((rdflib.term.URIRef('http://www.w3.org/2002/07/owl#onProperty'), rdflib.term.URIRef('http://www.example.org/hasProperty')), (rdflib.term.URIRef('http://www.w3.org/2002/07/owl#someValuesFrom'), rdflib.term.URIRef('http://www.example.org/color')))))]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Complex failure\n",
    "\n",
    "Now let's be a little sneaky -- as usual, our \"dye\" node will add \"color\" to the clothes, but let's leverage our ontological power to _remove_ the \"clean\" state!"
   ],
   "id": "36fb86b51a117df2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T19:57:18.617810Z",
     "start_time": "2025-08-27T19:57:18.614744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@pwf.as_function_node\n",
    "def dye_with_cancel(clothes: Clothes, color=\"blue\") -> u(\n",
    "    Clothes,\n",
    "    triples=(EX.hasProperty, EX.color),\n",
    "    derived_from=\"inputs.clothes\",\n",
    "    cancel=(EX.hasProperty, EX.cleaned)\n",
    "):\n",
    "    return clothes"
   ],
   "id": "3055fbc547280d91",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We fail, as expected. The error messages for failed ontology validations are still extremely opaque, but we can see that the upstream node `'cancel'`s the `.../cleaned` property, while the downstream type hint still requires `#someValuesFrom` `.../cleaned`.",
   "id": "599404a35b15ef6b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T19:57:18.715191Z",
     "start_time": "2025-08-27T19:57:18.624786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "my_wf_with_cancellation = pwf.Workflow(\"my_wf_with_cancellation\")\n",
    "my_wf_with_cancellation.washed_clothes = wash(Clothes())\n",
    "my_wf_with_cancellation.dyed_clothes = dye_with_cancel(my_wf_with_cancellation.washed_clothes)\n",
    "try:\n",
    "    my_wf_with_cancellation.money = sell(my_wf_with_cancellation.dyed_clothes)\n",
    "except ChannelConnectionError as e:\n",
    "    print(e)"
   ],
   "id": "912ab5035ea69c03",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The channel /my_wf_with_cancellation/dyed_clothes.clothes (<class 'pyiron_workflow.mixin.injection.OutputDataWithInjection'>) has the correct type (<class 'pyiron_workflow.channels.OutputData'>) to connect with /sell.clothes (<class 'pyiron_workflow.channels.InputData'>), but is not a valid connection.Please check type hints, etc. /my_wf_with_cancellation/dyed_clothes.clothes.type_hint = typing.Annotated[__main__.Clothes, ('triples', (rdflib.term.URIRef('http://www.example.org/hasProperty'), rdflib.term.URIRef('http://www.example.org/color')), 'derived_from', 'inputs.clothes', 'extra', {'cancel': (rdflib.term.URIRef('http://www.example.org/hasProperty'), rdflib.term.URIRef('http://www.example.org/cleaned'))})]; /sell.clothes.type_hint = typing.Annotated[__main__.Clothes, ('uri', rdflib.term.URIRef('http://www.example.org/Clothes'), 'restrictions', (((rdflib.term.URIRef('http://www.w3.org/2002/07/owl#onProperty'), rdflib.term.URIRef('http://www.example.org/hasProperty')), (rdflib.term.URIRef('http://www.w3.org/2002/07/owl#someValuesFrom'), rdflib.term.URIRef('http://www.example.org/cleaned'))), ((rdflib.term.URIRef('http://www.w3.org/2002/07/owl#onProperty'), rdflib.term.URIRef('http://www.example.org/hasProperty')), (rdflib.term.URIRef('http://www.w3.org/2002/07/owl#someValuesFrom'), rdflib.term.URIRef('http://www.example.org/color')))))]\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# It's alpha\n",
    "\n",
    "So far this has worked splendidly... for the particular test cases we're looking at. This is an alpha-feature and we neither support all possible `pyiron_workflow` node types, nor have we searched for and tested possible failing edge-cases among the supported node types. Thus, there is a safety valve. To turn off ontological validation, just go to the root-most object and set `._validate_ontologies = False`:"
   ],
   "id": "15d876ba21cee422"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T19:57:18.725789Z",
     "start_time": "2025-08-27T19:57:18.719703Z"
    }
   },
   "cell_type": "code",
   "source": [
    "my_silenced_ontology = pwf.Workflow(\"my_silenced_ontology\")\n",
    "my_silenced_ontology._validate_ontologies = False\n",
    "my_silenced_ontology.washed_clothes = wash(Clothes())\n",
    "my_silenced_ontology.dyed_clothes = dye_with_cancel(my_silenced_ontology.washed_clothes)\n",
    "my_silenced_ontology.money = sell(my_silenced_ontology.dyed_clothes)\n",
    "my_silenced_ontology()"
   ],
   "id": "93bfb07d4d377823",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'money__price': 10}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Node suggestions\n",
    "\n",
    "One of the advantages of graph-based workflows with hinted IO channels is facilitating guided workflow creation. Given a hinted channel instance in the context of some workflow, we can ask for suggestions of other channels with which to form a connection in the same, sibling graph context:"
   ],
   "id": "c612162f836d4c76"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T19:57:18.775605Z",
     "start_time": "2025-08-27T19:57:18.731698Z"
    }
   },
   "cell_type": "code",
   "source": [
    "wf = pwf.Workflow(\"ontoflow\")\n",
    "wf.make = prepare_pizza()\n",
    "wf.eat = eat_pizza()\n",
    "suggestions = suggest.suggest_connections(wf.eat.inputs.meal)\n",
    "for (node, channel) in suggestions:\n",
    "    print(node.full_label, channel.label)"
   ],
   "id": "7e01728625255664",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ontoflow/make pizza\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Similarly, given a corpus of node classes, we can ask for which nodes have at least one commensurate input/output with which our channel might connect. After adding such a node to our graph, we can leverage the connection suggester to see which channel(s) are appropriate.",
   "id": "c22ef9a507bb2230"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T19:57:18.871494Z",
     "start_time": "2025-08-27T19:57:18.785145Z"
    }
   },
   "cell_type": "code",
   "source": "suggest.suggest_nodes(wf.eat.inputs.meal, pwf.std.UserInput, prepare_pizza, wash)",
   "id": "4233ff3f954aa8ba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[__main__.prepare_pizza]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Suggestion limitations\n",
    "\n",
    "When searching for new upstream nodes to add, the current implementation only looks at the immediate node, and not possible trees of upstream nodes. Returning to our clothes example, we can see that there is no _single_ suggestion for the `sell` node, because it requires clothes that are both dyed _and_ coloured, but our other nodes only provide one of these at a time!"
   ],
   "id": "afac4e0b565c801e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T19:57:18.880846Z",
     "start_time": "2025-08-27T19:57:18.877286Z"
    }
   },
   "cell_type": "code",
   "source": [
    "clothing_nodes = wash, dye, dye_with_cancel, sell\n",
    "\n",
    "wf = pwf.Workflow(\"working_backwards\")\n",
    "wf.money = sell()\n",
    "suggest.suggest_nodes(wf.money, *clothing_nodes)"
   ],
   "id": "df8ba4cf778b75d3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Of course working backwards a single step still works fine for lots of nodes, e.g. for `dye` we will take _anything_ that gives us clothes!",
   "id": "a32732a594de4540"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T19:57:19.147080Z",
     "start_time": "2025-08-27T19:57:18.895584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "wf = pwf.Workflow(\"single_step_back\")\n",
    "wf.dyed_clothes = dye()\n",
    "suggest.suggest_nodes(wf.dyed_clothes, *clothing_nodes)"
   ],
   "id": "eb0517eb5d999901",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[__main__.wash, __main__.dye, __main__.dye_with_cancel]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "And when we look _downstream_ we have the advantage of knowing the entire upstream graph concretely, so there we are able to see options for fulfilling these more complex demands.",
   "id": "68c785add89b7f53"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T19:57:19.700788Z",
     "start_time": "2025-08-27T19:57:19.152192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "wf = pwf.Workflow(\"downstream\")\n",
    "wf.dyed_clothes = dye(Clothes())\n",
    "wf.washed_clothes = wash(wf.dyed_clothes)\n",
    "suggestions = suggest.suggest_nodes(wf.washed_clothes, *clothing_nodes)\n",
    "assert(sell in suggestions)\n",
    "print(suggestions)"
   ],
   "id": "9e0064e26ce9e554",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<class '__main__.wash'>, <class '__main__.dye'>, <class '__main__.dye_with_cancel'>, <class '__main__.sell'>]\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Complex workflows\n",
    "\n",
    "Ontological validation is still an alpha feature, and not all edge cases have been thoroughly tested. However, we can see below that even complex graphs including macros, dataclass nodes, and for-loops are able to run and validate."
   ],
   "id": "b99e02ecb6d584a5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T19:57:20.415626Z",
     "start_time": "2025-08-27T19:57:19.705734Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EX = rdflib.Namespace(\"http://www.example.org/\")\n",
    "\n",
    "@pwf.as_dataclass_node\n",
    "class QandA:\n",
    "    question: u(str, uri=EX.Query) = \"question text\"\n",
    "    answer: int = 42\n",
    "\n",
    "@pwf.as_function_node\n",
    "def Question(phrasing: str) -> u(str, uri=EX.Query):\n",
    "    question = phrasing\n",
    "    return question\n",
    "\n",
    "@pwf.as_function_node\n",
    "def Picard(interaction: QandA.dataclass) -> u(str, uri=EX.Response):\n",
    "    response = (\n",
    "        \"There... Are... Four... Lights!\"\n",
    "        if interaction.answer == 5\n",
    "        else \"A ship is coming to take him back to the Enterprise\"\n",
    "    )\n",
    "    return response\n",
    "\n",
    "@pwf.as_macro_node\n",
    "def GulMadred(self, question: u(str, uri=EX.Query), answer: int) -> u(str, uri=EX.Response):\n",
    "    self.interaction = QandA(question=question, answer=answer)\n",
    "    self.response = Picard(self.interaction)\n",
    "    return self.response\n",
    "\n",
    "wf = pwf.Workflow(\"star_trek\")\n",
    "wf.question = Question(\"How many lights are there?\")\n",
    "wf.chain = pwf.for_node(\n",
    "    body_node_class=GulMadred,\n",
    "    iter_on=\"answer\",\n",
    "    question=wf.question,\n",
    "    answer=[4, 5],\n",
    "    output_as_dataframe=False,\n",
    ")\n",
    "wf()"
   ],
   "id": "216f7e5e96946a34",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liamhuber/dev/pyiron/semantikon/semantikon/ontology.py:48: FutureWarning: semantikon_class is experimental - triples may change in the future\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'chain__answer': [4, 5],\n",
       " 'chain__response': ['A ship is coming to take him back to the Enterprise',\n",
       "  'There... Are... Four... Lights!']}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Parsing macros\n",
    "\n",
    "The observant reader will not that the above example _ought_ to fail to parse. Stretching our Star Trek reference to its utmost, `GulMadred` promises he will return a `EX.BrokenMan`, but `Picard` remains ever our `EX.StalwartCaptain`.\n",
    "\n",
    "`pyiron_workflow` uses `value_receiver` to pass information into (macro input -> child node input) and out of (child node output -> macro output) subgraphs. These show up in the `\"edges\"` list along with other child-child edge in the dictionary representation of our workflows that we pass to `semantikon` for validation.\n",
    "\n",
    "However, despite the fact that both tools employ connected concepts, I haven't yet managed to get the plumbing set up for the ontology to raise an error when we break ontological promises as we pass across the subgraph barrier.\n",
    "\n",
    "This is more easily seen in this simpler example, which should fail for all but one of the nodes:"
   ],
   "id": "1a2b1bc1885cd5c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T19:57:20.545273Z",
     "start_time": "2025-08-27T19:57:20.420199Z"
    }
   },
   "cell_type": "code",
   "source": [
    "EX = rdflib.Namespace(\"http://www.example.org/\")\n",
    "\n",
    "@pwf.as_function_node\n",
    "def AddOnetology(x: u(int, uri=EX.Input)) -> u(int, uri=EX.Output):\n",
    "    y = x + 1\n",
    "    return y\n",
    "\n",
    "@pwf.as_macro_node\n",
    "def MatchingWrapper(self, x_outer: u(int, uri=EX.Input)) -> u(int, uri=EX.Output):\n",
    "    self.add = AddOnetology(x_outer)\n",
    "    return self.add\n",
    "\n",
    "@pwf.as_macro_node\n",
    "def MismatchingInput(self, x_outer: u(int, uri=EX.NotInput)) -> u(int, uri=EX.Output):\n",
    "    self.add = AddOnetology(x_outer)\n",
    "    return self.add\n",
    "\n",
    "@pwf.as_macro_node\n",
    "def MismatchingOutput(self, x_outer: u(int, uri=EX.NotInput)) -> u(int, uri=EX.NotOutput):\n",
    "    self.add = AddOnetology(x_outer)\n",
    "    return self.add\n",
    "\n",
    "wf = pwf.Workflow(\"parent_matches_child\")\n",
    "wf.ok = MatchingWrapper(1)\n",
    "wf()"
   ],
   "id": "6020a83d03588297",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ok__add': 2}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T19:57:20.672367Z",
     "start_time": "2025-08-27T19:57:20.554814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "try:\n",
    "    wf = pwf.Workflow(\"parent_wrong_input\")\n",
    "    wf.should_fail_in = MismatchingInput(2)\n",
    "    raise RuntimeError(\"Should fail to validate before this\")\n",
    "except ValueError as e:\n",
    "    print(e)"
   ],
   "id": "76f0aa956d11279f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ontological error on value passing: {'missing_triples': [], 'incompatible_connections': [(rdflib.term.URIRef('MismatchingInput.add.inputs.x'), rdflib.term.URIRef('MismatchingInput.inputs.x_outer'), [rdflib.term.URIRef('http://www.example.org/Input'), rdflib.term.URIRef('http://www.example.org/NotInput')], [rdflib.term.URIRef('http://www.example.org/NotInput')])], 'distinct_units': {}}\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T19:57:20.805891Z",
     "start_time": "2025-08-27T19:57:20.686527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "try:\n",
    "    wf = pwf.Workflow(\"parent_wrong_output\")\n",
    "    wf.should_fail_in = MismatchingOutput(2)\n",
    "    raise RuntimeError(\"Should fail to validate before this\")\n",
    "except ValueError as e:\n",
    "    print(e)"
   ],
   "id": "57868aa0f68b0175",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ontological error on value passing: {'missing_triples': [], 'incompatible_connections': [(rdflib.term.URIRef('MismatchingOutput.outputs.add'), rdflib.term.URIRef('MismatchingOutput.add.outputs.y'), [rdflib.term.URIRef('http://www.example.org/NotOutput'), rdflib.term.URIRef('http://www.example.org/Output')], [rdflib.term.URIRef('http://www.example.org/Output')]), (rdflib.term.URIRef('MismatchingOutput.add.inputs.x'), rdflib.term.URIRef('MismatchingOutput.inputs.x_outer'), [rdflib.term.URIRef('http://www.example.org/Input'), rdflib.term.URIRef('http://www.example.org/NotInput')], [rdflib.term.URIRef('http://www.example.org/NotInput')])], 'distinct_units': {}}\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Units\n",
    "\n",
    "`semantikon` annotations also allow us to specify physical units. When present, these are included in the ontological validation just like the other ontological terms.\n",
    "\n",
    "As such, we have no problem making same-unit connections:"
   ],
   "id": "7cf5e95f5ef33175"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T19:57:20.895580Z",
     "start_time": "2025-08-27T19:57:20.810673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@pwf.as_function_node\n",
    "def Distance(x: u(float, units=\"meter\")) -> u(float, derived_from=\"inputs.x\"):\n",
    "    return x\n",
    "\n",
    "@pwf.as_function_node\n",
    "def Speed(\n",
    "        dx: u(float, units=\"meter\"), dt: u(float, units=\"second\")\n",
    ") -> u(float, units=\"meter/second\"):\n",
    "    s = dx/dt\n",
    "    return s\n",
    "\n",
    "wf = pwf.Workflow(\"speedometer\")\n",
    "wf.dx = Distance(100)\n",
    "wf.speed = Speed(dx=wf.dx)"
   ],
   "id": "7fa30c5bb66141ee",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "With incompatible units, we get an exception at connection time, just like with other ontological failures:",
   "id": "3c1f02dfc7a719a1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T19:57:20.945969Z",
     "start_time": "2025-08-27T19:57:20.899655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@pwf.as_function_node\n",
    "def NanoTime(t: u(float, units=\"nanosecond\")) -> u(float, units=\"nanosecond\"):\n",
    "    return t\n",
    "\n",
    "wf.dt = NanoTime(10)\n",
    "try:\n",
    "    wf.speed.inputs.dt = wf.dt\n",
    "except ChannelConnectionError as e:\n",
    "    print(e)\n",
    "    wf.remove_child(wf.dt)"
   ],
   "id": "bad9905df584134c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The channel /speedometer/dt.t (<class 'pyiron_workflow.mixin.injection.OutputDataWithInjection'>) has the correct type (<class 'pyiron_workflow.channels.OutputData'>) to connect with /speedometer/speed.dt (<class 'pyiron_workflow.channels.InputData'>), but is not a valid connection.Please check type hints, etc. /speedometer/dt.t.type_hint = typing.Annotated[float, ('units', 'nanosecond')]; /speedometer/speed.dt.type_hint = typing.Annotated[float, ('units', 'second')]\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "With correct units, it works fine",
   "id": "1960f91b859f1516"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T19:57:21.072776Z",
     "start_time": "2025-08-27T19:57:20.956526Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@pwf.as_function_node\n",
    "def Time(t: u(float, units=\"second\")) -> u(float, units=\"second\"):\n",
    "    return t\n",
    "\n",
    "wf.dt = Time(10)\n",
    "wf.speed.inputs.dt = wf.dt\n",
    "wf()"
   ],
   "id": "a918e2e7d80b8376",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'speed__s': 10.0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "(Note that inheriting units with `derived_from=` in the annotation is not currently working like other ontological properties: https://github.com/pyiron/semantikon/issues/256)",
   "id": "dafffcc1823b711f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Known Issues\n",
    "\n",
    "- This implementation naively creates a circular dependence: the `channels` module needs the `knowledge` module to evaluate the ontological validity of new connections, but the `knowledge` module relies on `workflow` and `nodes.composite` to parse graphs, and these in turn depend on `channels`. For now, we avoid dealing with this by importing `knowledge` locally in `channels` when it's time to use the ontology.\n",
    "- There are strings everywhere. The ontological features rely heavily on dictionaries, which are tough to type check and rely on string-based key access. E.g., when we want to see if the ontological validation raised any errors, we need to manually check on two dictionary entries by name. This is fragile.\n",
    "- It is heinously inefficient. At every new ontologically-hinted connection, we reconstruct the entire recipe dictionary before positing the new connection and checking its validity. I'm not sure we'll get around validation operating on the entire graph, but we should adjust `pyiron_workflow` to store more recipe information at the class level where it is statically known (macros, function nodes, etc)\n",
    "- This is not _at all_ edge-case tested. This works for the special cases we test here, and there's no generic guarantee this functionality works for more complex ontologies or more complex workflows.\n",
    "- Upstream suggestions are limited to a _single_ suggestion, we don't do any tree construction to create upstream subgraphs that leverage trees of nodes in order to fulfill ontological demands. We _could_, but a brute-force attack would scale horribly with the node corpus.\n",
    "- Overhead: importing `semantikon.ontology` takes the better part of a second. We delay the import until the last moment, so this only impacts graphs where both ends of a connection are annotated, but there the import time is slow enough to be noticed on human scales.\n",
    "- The failure to parse macro/child IO transfers ontologically (previous section)\n",
    "\n",
    "# Open Questions\n",
    "\n",
    "- Will macros with explicitly defined IO that conflicts with auto-generated IO fail under any circumstances?\n"
   ],
   "id": "c1e37915be9898fb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T19:57:21.085456Z",
     "start_time": "2025-08-27T19:57:21.083744Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "54d1820a5d64befd",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
